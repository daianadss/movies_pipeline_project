# Projeto de ETL e An√°lise de Dados de Filmes

Este reposit√≥rio cont√©m um projeto de Engenharia de Dados focado na constru√ß√£o de um pipeline ETL (Extract, Transform, Load) para dados de filmes. O objetivo √© praticar as etapas de extra√ß√£o, limpeza, transforma√ß√£o e carga de dados, culminando em um conjunto de dados pronto para an√°lise e algumas an√°lises iniciais.

---

## üìÅ Dados

Os datasets brutos utilizados neste projeto s√£o:
- `movies_metadata.csv`: Cont√©m metadados de aproximadamente 45.000 filmes.
- `ratings.csv`: Cont√©m 26 milh√µes de avalia√ß√µes de filmes.

Ambos os datasets foram obtidos do [The Movies Dataset no Kaggle](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/).

**Para replicar o projeto, por favor, baixe estes arquivos diretamente do Kaggle e coloque-os na pasta `data/raw/` do seu projeto clonado.**

A pasta `data/processed/` (onde o `movies_metadata_cleaned.csv` √© salvo ap√≥s a fase de Transforma√ß√£o) **n√£o √© versionada no Git** para manter o reposit√≥rio leve e focado no c√≥digo.

---

## üìÇ Estrutura do Projeto

- `data/`: Cont√©m os datasets utilizados.
    - `data/raw/`: Dados brutos originais. **Esta pasta √© ignorada pelo Git.**
    - `data/processed/`: Dados ap√≥s as etapas de limpeza e transforma√ß√£o. **Esta pasta tamb√©m √© ignorada pelo Git.**
- `notebooks/`: Cont√©m os scripts Python (ou notebooks Jupyter) que realizam as opera√ß√µes de ETL e EDA.
    - `01_eda_movies_metadata.py`: Script principal que realiza a extra√ß√£o, limpeza e transforma√ß√£o dos metadados dos filmes, al√©m de integrar dados de avalia√ß√µes.
    - `02_load_data_to_sqlite.py` (A ser implementado): Script respons√°vel por carregar os dados transformados em um banco de dados SQLite.
- `.gitignore`: Configura quais arquivos e pastas o Git deve ignorar ao versionar o projeto.

---

## üöÄ Fases do Pipeline ETL

### üì¶ Fase de Extra√ß√£o (E)

Os dados s√£o extra√≠dos diretamente dos arquivos CSV brutos (`movies_metadata.csv` e `ratings.csv`) localizados na pasta `data/raw/`.

### üßπ Fase de Transforma√ß√£o (T)

Esta fase, detalhada no script `01_eda_movies_metadata.py`, envolveu a limpeza e o enriquecimento intensivo dos datasets:

-   **Tratamento de Dados Aninhados:** Extra√ß√£o e normaliza√ß√£o de informa√ß√µes de dicion√°rios e listas aninhadas em colunas como `genres`, `production_companies`, `spoken_languages`, etc.
-   **Limpeza e Convers√£o de Tipos:**
    -   `release_date`: Convertida para o tipo `datetime`, e extra√≠do o `release_year`.
    -   `budget` e `revenue`: Convertidas para o tipo num√©rico (`float`), com tratamento de valores n√£o num√©ricos e preenchimento de nulos com `0`.
    -   `id`: Garantido como num√©rico (`int`) e sem valores nulos.
    -   `vote_average` e `vote_count`: Convertidas para num√©rico e nulos preenchidos com `0`.
-   **Tratamento de Valores Ausentes:** Aplica√ß√£o de estrat√©gias como remo√ß√£o de linhas (para `title`, `id`, `release_date`) e preenchimento de nulos (para colunas num√©ricas de votos, or√ßamento e receita) para garantir a integridade dos dados.
-   **Agrega√ß√£o e Enriquecimento:**
    -   O dataset `ratings.csv` foi agregado para calcular a `average_rating` (m√©dia de avalia√ß√µes) e `ratings_count` (contagem de avalia√ß√µes) por filme.
    -   Essas m√©tricas foram ent√£o mescladas (`left join`) com o `df_metadata_clean` para criar um `df_final` enriquecido, contendo os metadados dos filmes e suas informa√ß√µes de avalia√ß√£o.
-   **Persist√™ncia:** O `df_final` foi salvo em formato CSV (`movies_metadata_cleaned.csv`) na pasta `data/processed/`, marcando o fim da fase de Transforma√ß√£o.

### üíæ Fase de Carga (L) - Pr√≥ximos Passos

A pr√≥xima etapa √© carregar o dataset processado (`movies_metadata_cleaned.csv`) em um banco de dados relacional (SQLite) para an√°lises e consultas posteriores. Esta fase ser√° implementada no script `02_load_data_to_sqlite.py`.

---

## üèÉ‚Äç‚ôÄÔ∏è Como Executar

1.  **Pr√©-requisitos:** Certifique-se de ter Python (vers√£o 3.x) e as bibliotecas necess√°rias instaladas (e.g., `pandas`, `numpy`, `sqlite3`). Recomenda-se usar um ambiente virtual.
2.  **Clone o Reposit√≥rio:**
    ```bash
    git clone [https://github.com/seu-usuario/etl-movie-data.git](https://github.com/seu-usuario/etl-movie-data.git)
    cd etl-movie-data
    ```
    (Lembre-se de substituir `seu-usuario` pelo seu nome de usu√°rio do GitHub e `etl-movie-data` pelo nome do seu reposit√≥rio).
3.  **Baixe os Dados Brutos:** Acesse o link do Kaggle fornecido na se√ß√£o "Dados" acima e baixe os arquivos `movies_metadata.csv` e `ratings.csv`.
4.  **Organize os Dados Brutos:** Crie uma pasta `data/raw/` na raiz do seu projeto (se ela ainda n√£o existir automaticamente pelo clone) e coloque os arquivos CSV baixados dentro dela.
5.  **Execute a Fase de Transforma√ß√£o:**
    ```bash
    python notebooks/01_eda_movies_metadata.py
    ```
    Este script ir√° limpar, transformar e salvar o dataset `movies_metadata_cleaned.csv` na pasta `data/processed/`.
6.  **Execute a Fase de Carga (Futuro):** Ap√≥s a implementa√ß√£o, o script `02_load_data_to_sqlite.py` ser√° executado para carregar os dados processados no SQLite.

---
